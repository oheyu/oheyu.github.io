[{"content":"\rmemcpy() 函数是 C 标准库中用于内存操作的一个重要函数，它被广泛用于在内存中复制数据块。在系统编程和低级数据操作中，memcpy() 是一个常用且高效的工具。\nmemcpy() 函数的概述 memcpy() 函数用于将指定数量的字节从一个内存位置复制到另一个内存位置。它的操作是直接的、低级的，不会进行任何数据类型的转换或优化。在 string.h 头文件中，memcpy() 的定义如下：\n1 2 3 #include \u0026lt;string.h\u0026gt; void *memcpy(void *dest, const void *src, size_t n); 其中，对于参数而言：\ndest：目标内存地址的指针，表示数据的复制去向。 src：源内存地址的指针，表示数据的复制来源。 n：要复制的字节数。 对于返回值，该函数返回一个通用指针，该指针指向 dest。\n理解 void*。\nvoid* 是一种通用指针（generic pointer）。不同于空指针 NULL 表示一个不指向任何有效内存的特殊指针值，void* 指针可以指向内存中的某个位置，但其指向的数据类型是未确定的（通用的）。\n也正是因为 void* 指针不包含类型信息，所以它是类型不安全的。这意味着我们在使用 void* 时，必须确保正确的将其转换为合适的类型。此外，void* 指针也不能进行指针算术运算（如递增、递减），因为它不包含类型信息，编译器不知道要增加（减少）多少字节。最后，void* 指针也不能被直接解引用，必须将其转换为特定类型的指针。\n为什么 memcpy() 的返回值 void* 指向目标内存地址？\n函数链式调用的便利性：char *copied_data = memcpy(buffer, source, size);，在这条语句中，memcpy() 返回的指针可以直接被用于 copied_data，不需要额外的变量或操作。\nmemcpy() 函数的使用示例 以下是一个使用 memcpy() 函数将一个数组的数据复制到另一个数组的示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char src[] = \u0026#34;Hello, World!\u0026#34;; char dest[20]; // 使用 memcpy 函数复制数据 memcpy(dest, src, strlen(src) + 1); // +1 是为了包括字符串的终止符 \u0026#39;\\0\u0026#39; printf(\u0026#34;Source: %s\\n\u0026#34;, src); printf(\u0026#34;Destination: %s\\n\u0026#34;, dest); return 0; } 在这个示例中：\n我们定义了一个源数组 src，其中包含字符串 \u0026quot;Hello, World!\u0026quot;。 我们定义了一个目标数组 dest，大小足以容纳源数组的内容。 我们使用 memcpy() 函数将 src 数组的内容复制到 dest 数组。 复制操作包括了字符串的终止符 '\\0'，以确保目标数组中的字符串正确终止。 memcpy() 函数的工作原理 memcpy() 函数的工作原理是直接在内存级别复制字节数据。它不进行任何类型检查或优化，而是逐字节地将数据从源地址复制到目标地址。\n逐字节复制：\nmemcpy() 从源地址 src 开始，逐字节地读取数据，并将这些数据写入到目标地址 dest。 复制的字节数由参数 n 指定。 指针操作：\n源地址和目标地址通过指针传递，因此函数能够直接操作内存地址。 复制操作是按照内存地址的顺序进行的，从 src 开始依次向后复制 n 个字节到 dest。 不处理重叠：\nmemcpy() 假设源和目标内存区域不会重叠。 如果源和目标区域重叠，memcpy() 的行为未定义，可能会导致数据损坏。在这种情况下，应该使用 memmove() 函数。 memcpy() 函数的使用注意事项 内存重叠问题：\nmemcpy() 假设源和目标区域不重叠。如果内存区域重叠，可能会导致数据复制的过程出现问题，数据可能会被覆盖或损坏。 如果你需要在重叠的内存区域之间复制数据，应该使用 memmove()，它能够正确处理重叠区域。 目标内存大小：\n确保目标内存区域 dest 足够大，能够容纳复制的数据。如果目标内存区域不够大，可能会导致内存越界，造成未定义行为或程序崩溃。 类型不匹配：\nmemcpy() 直接复制字节数据，不关心数据的类型。因此，目标和源数据类型不匹配时，需要小心，确保数据类型和大小一致。 速度与效率：\nmemcpy() 是一个低级别的、直接的内存操作函数，通常比逐个元素复制数据更快，但它不进行任何优化。 在处理大块数据时，memcpy() 通常比手动逐字节复制更高效。 memcpy() 函数与其他内存操作函数的比较 memmove() 函数：\nmemmove() 函数类似于 memcpy() 函数，但它能够正确处理源和目标内存区域重叠的情况。 memmove() 在内部处理重叠区域的数据，确保数据不会在复制过程中被覆盖。 strcpy() 函数：\nstrcpy() 函数专用于复制以 \\0 结尾的字符串。 memcpy() 函数可以复制任意类型的内存数据，而不仅仅是字符串。 memset() 函数：\nmemset() 用于将内存区域中的所有字节设置为指定的值。 memcpy() 用于从一个内存区域复制数据到另一个内存区域。 memcpy() 函数的常见应用场景 数据复制：\nmemcpy() 常用于在内存中复制数据块，例如从一个数组复制到另一个数组。 在网络编程中，memcpy() 可以用于将数据包复制到缓冲区。 结构体复制：\n可以用于将一个结构体的数据复制到另一个相同类型的结构体中。例如，复制一个结构体数组的元素到另一个结构体数组。 内存初始化：\n使用 memcpy() 将初始化数据块复制到目标内存区域，以快速设置内存的初始状态。例如，初始化缓冲区或缓存数据。 文件处理：\n在文件 I/O 操作中，memcpy() 可以用于将文件内容读入到内存缓冲区，或将缓冲区的数据写入到文件。 memcpy() 函数的使用代码示例 以下是使用 memcpy() 函数复制结构体数据的示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; typedef struct { int id; char name[20]; float salary; } Employee; int main() { Employee emp1 = {1, \u0026#34;John Doe\u0026#34;, 50000.0}; Employee emp2; // 使用 memcpy 复制结构体数据 memcpy(\u0026amp;emp2, \u0026amp;emp1, sizeof(Employee)); printf(\u0026#34;Employee 2 - ID: %d, Name: %s, Salary: %.2f\\n\u0026#34;, emp2.id, emp2.name, emp2.salary); return 0; } 在这个示例中：\n我们定义了一个 Employee 结构体，并创建了两个 Employee 类型的变量 emp1 和 emp2。 使用 memcpy() 将 emp1 的数据复制到 emp2，包括 id、name 和 salary。 复制后，我们打印 emp2 的数据，验证 memcpy() 的复制效果。 ","permalink":"https://oheyu.github.io/zh/posts/tech/memcpy%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/","summary":"memcpy() 函数是 C 标准库中用于内存操作的一个重要函数，它被广泛用于在内存中复制数据块。在系统编程和低级数据操作中，memcpy() 是一个常用且高效的","title":"memcpy()函数详解"},{"content":"\rLinux 手册页（man pages）是每个 Linux 用户和开发者的重要资源。它们提供了关于各种命令、系统调用、库函数、文件格式等的详细信息。手册页分为多个章节，每个章节涵盖特定类型的内容。\n一. 用户命令（User Commands） 章节编号：1\n内容：普通用户可以运行的命令和程序。\n适用场景：查找和学习日常使用的命令，如 ls、cp、grep 等。\n示例：\n1 man 1 ls 二. 系统调用（System Calls） 章节编号：2\n内容：操作系统内核提供的系统调用。\n适用场景：编写与操作系统内核直接交互的低级程序，例如涉及文件操作、进程控制等。\n示例：\n1 man 2 open 三. 库函数（Library Functions） 章节编号：3\n内容：C 标准库（libc）函数及其他库函数。\n适用场景：使用 C 语言编程时，查找标准库函数的用法和参数，例如字符串处理、数学函数等。\n示例：\n1 man 3 printf 四. 特殊文件（Special Files） 章节编号：4\n内容：设备文件和驱动程序。\n适用场景：与硬件设备交互或开发驱动程序时，查找设备文件的详细信息。\n示例：\n1 man 4 tty 五. 文件格式（File Formats and Conventions） 章节编号：5\n内容：各种文件格式、配置文件和协议描述。\n适用场景：编写或解析特定格式的文件时，了解文件格式的细节。\n示例：\n1 man 5 passwd 六. 游戏和杂项（Games and Screensavers） 章节编号：6\n内容：游戏和屏幕保护程序。\n适用场景：查找和了解系统上安装的游戏或屏幕保护程序。\n示例：\n1 man 6 snake 七. 杂项（Miscellaneous） 章节编号：7\n内容：与系统相关的杂项信息，包括宏包、惯例和协议。\n适用场景：查找与网络协议、文件系统、进程间通信等相关的高级主题。\n示例：\n1 man 7 socket 八. 系统管理命令（System Administration Commands） 章节编号：8\n内容：系统管理员使用的命令。\n适用场景：进行系统维护、配置和管理时，查找管理员级别的命令。\n示例：\n1 man 8 mount 九. 内核例程（Kernel Routines） 章节编号：9\n内容：内核开发和模块编程相关的函数和宏。\n适用场景：进行 Linux 内核开发或编写内核模块时，查找内核函数和数据结构的详细信息。\n示例：\n1 man 9 printk 总结 用户命令：日常使用的命令和工具。 系统调用：与操作系统内核交互的函数。 库函数：标准库和其他库提供的函数。 特殊文件：设备文件和驱动程序信息。 文件格式：配置文件和文件格式描述。 游戏和杂项：系统上的游戏和屏幕保护程序。 杂项：高级主题和系统相关信息。 系统管理命令：管理员使用的命令。 内核例程：内核开发相关的信息。 ","permalink":"https://oheyu.github.io/zh/posts/tech/linux%E6%89%8B%E5%86%8C%E9%A1%B5%E6%8C%87%E5%8D%97%E4%BA%86%E8%A7%A3%E5%90%84%E7%AB%A0%E8%8A%82%E5%8F%8A%E5%85%B6%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/","summary":"Linux 手册页（man pages）是每个 Linux 用户和开发者的重要资源。它们提供了关于各种命令、系统调用、库函数、文件格式等的详细信息。手册页分为多个章","title":"Linux手册页指南：了解各章节及其使用场景"},{"content":"\r在使用 PyTorch 进行模型训练时，为什么需要设置训练模式？如何计算每个 epoch 的平均损失？今天，我们来唠一唠。\n一、模型的训练模式 在训练神经网络模型时，特别是在使用 PyTorch 框架时，我们通常会看到类似如下的代码：\n1 model.train() 这行代码将模型设置为训练模式。这对于一些特定的层，如 Dropout 和 Batch Normalization，尤为重要。让我们深入了解一下原因。\n1.1 Dropout 层 Dropout 是一种正则化技术，旨在防止过拟合。在训练过程中，Dropout 会随机地将一部分神经元的输出设为零，从而防止模型对训练数据过拟合。然而，在测试和评估模型时，我们希望使用所有的神经元。因此，Dropout 层在训练和测试时的行为有所不同：\n训练模式：随机屏蔽部分神经元。 评估模式：使用所有神经元，不进行屏蔽。 1.2 Batch Normalization 层 Batch Normalization 通过在每个小批次上标准化输入来加速训练和提高稳定性。在训练和测试时，它的行为也不同：\n训练模式：使用当前批次的数据计算均值和方差进行标准化。 评估模式：使用在训练过程中积累的全局均值和方差进行标准化。 因此，将模型设置为训练模式（model.train()）确保了这些层在训练时表现正确。如果忘记了这一步，可能会导致训练效果不佳或者评估结果不准确。\n二、计算每个 epoch 的平均损失 在训练过程中，我们需要跟踪模型的性能，其中一个常用的指标是损失（loss）。损失函数用于衡量模型预测值与实际值之间的误差。在每个 epoch 结束时，计算其平均损失是一个常见做法。以下是计算每个 epoch 平均损失的代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def train(model, device, trainloader, criterion, optimizer, num_epochs): model.train() train_losses = [] for epoch in range(num_epochs): running_loss = 0.0 for inputs, labels in tqdm(trainloader, desc=f\u0026#34;Epoch [{epoch+1}/{num_epochs}]\u0026#34;): inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() epoch_loss = running_loss / len(trainloader) train_losses.append(epoch_loss) print(f\u0026#34;Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\u0026#34;) return train_losses 2.1 详细解释： Epoch：一个 epoch 表示模型完整地遍历一次训练数据集。在一个 epoch 内，模型会处理多个批次（batch）的数据。\nBatch：为了处理大型数据集，训练数据通常被分割成多个小批次。每个批次中的数据量称为 batch size。\n在每个 epoch 的训练过程中，我们会累加每个批次的损失到 running_loss 中。running_loss 记录了当前 epoch 中所有批次的总损失。\nlen(trainloader) 表示训练数据加载器中批次的数量。为了计算当前 epoch 的平均损失，我们将 running_loss 除以批次的数量 len(trainloader)。这种方法提供了一个衡量标准，表示在整个训练周期内，模型在所有训练数据上的平均损失。\n2.2 代码解析： 1 epoch_loss = running_loss / len(trainloader) 这行代码计算当前 epoch 的平均损失。running_loss 是所有批次的总损失，将其除以批次数量，得到每个批次的平均损失。这有助于监控训练过程中损失的变化，判断模型是否在逐渐收敛。\n总结 在训练模式下，Dropout 和 Batch Normalization 层的行为与评估模式不同，确保这些层在训练过程中表现正确至关重要。\n","permalink":"https://oheyu.github.io/zh/posts/tech/pytorch%E4%B8%AD%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%BC%8F%E5%92%8C%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97/","summary":"在使用 PyTorch 进行模型训练时，为什么需要设置训练模式？如何计算每个 epoch 的平均损失？今天，我们来唠一唠。 一、模型的训练模式 在训练神经网络模型时，特别是","title":"PyTorch中的训练模式和损失计算"},{"content":"\r在 C++ 中，逗号运算符 , 是一个有趣且常见的运算符，它允许在一个语句中计算多个表达式。虽然它的使用相对简单，但在某些情况下可能会引起混淆。\n逗号运算符的基本原理 逗号运算符 , 会依次计算其左侧和右侧的表达式，整个表达式的结果是右侧表达式的值。其基本用法如下：\n1 expression1, expression2 步骤 1：计算 expression1 并丢弃其结果。 步骤 2：计算 expression2 并返回其结果。 考虑以下例子：\n1 int x = (1, 024); 其中，\n逗号运算符 (1, 024) 会首先计算 1，然后计算 024。 024 是一个八进制数（因为前导零），其值为 2*8 + 4 = 20（十进制）。 最终，int x = (1, 024); 等效于 int x = 20;。 此外，我们也可以使用逗号运算符进行赋值：\n1 2 int y; y = 1,024; 其中：\n赋值运算符 = 的优先级高于逗号运算符，因此 y = 1,024; 实际上等效于 (y = 1), 024;。 首先计算 (y = 1)，将 1 赋值给 y。 然后计算 024，其值为八进制的 20，但其结果被丢弃。 最终，y 的值是 1。\n总结 逗号运算符 , 在 C++ 中允许在一个语句中计算多个表达式，并返回右侧表达式的结果。其主要用途包括：\n在循环中进行多变量操作。 在赋值或初始化语句中对多个表达式进行计算。 在赋值语句中使用逗号运算符时，需要注意赋值运算符的优先级以及表达式的计算顺序，以避免意外结果。例如：\n1 2 int y; y = (1, 024); // y 将被初始化为 20（八进制） 1 2 int y; y = 1,024; // y 将被赋值为 1 ","permalink":"https://oheyu.github.io/zh/posts/tech/%E7%90%86%E8%A7%A3cpp%E4%B8%AD%E7%9A%84%E9%80%97%E5%8F%B7%E8%BF%90%E7%AE%97%E7%AC%A6%E5%8F%8A%E5%85%B6%E5%9C%A8%E8%B5%8B%E5%80%BC%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","summary":"在 C++ 中，逗号运算符 , 是一个有趣且常见的运算符，它允许在一个语句中计算多个表达式。虽然它的使用相对简单，但在某些情况下可能会引起混淆。 逗号运算","title":"理解CPP中的逗号运算符及其在赋值中的应用"},{"content":"\r在C语言编程中，NULL字符（通常表示为 \\0）是一个关键的概念，尤其在处理字符串时。它标志着字符串的结束，并在许多函数和算法中起着至关重要的作用。本篇博客将详细解释NULL字符的作用、典型使用场景以及需要注意的事项。\n一、什么是 NULL 字符？ NULL字符是一个值为零的字符，表示字符串的终止。在C语言中，字符串实际上是一个字符数组，而NULL字符的存在是为了标志这个字符数组的结尾。\n1 char str[] = \u0026#34;Hello, world!\u0026#34;; 上面这个字符串数组str在内存中实际存储如下：\n1 H e l l o , w o r l d ! \\0 这里的\\0就是NULL字符，它表示字符串的结束。\n二、NULL 字符的作用 2.1 标志字符串的结束 NULL字符用于标识字符串的结尾，使得C语言中的字符串处理函数（如strlen、strcpy、printf等）能够正确地处理字符串。\n1 2 3 4 5 6 7 8 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char str[] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;Length of string: %zu\\n\u0026#34;, strlen(str)); // 输出 5 return 0; } 2.2 避免缓冲区溢出 在处理输入输出时，通过限定字符串长度并添加NULL字符，可以有效防止缓冲区溢出等安全问题。\n1 2 3 char buffer[10]; strncpy(buffer, \u0026#34;This is a long string\u0026#34;, sizeof(buffer) - 1); buffer[sizeof(buffer) - 1] = \u0026#39;\\0\u0026#39;; // 确保以 NULL 结尾 2.3 方便字符串操作 大多数C标准库函数都依赖NULL字符来确定字符串的长度和边界，使用NULL字符能够简化字符串操作。\n三、使用场景 3.1 字符串初始化 在定义和初始化字符串时，编译器会自动在末尾添加NULL字符。\n1 char str[] = \u0026#34;Hello\u0026#34;; // 实际大小是 6, 包括末尾的 NULL 字符 3.2 字符串操作函数 函数如strcpy、strcat等都会处理NULL字符，确保字符串正确终止。\n1 2 3 4 char dest[20]; strcpy(dest, \u0026#34;Hello\u0026#34;); strcat(dest, \u0026#34;, world!\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, dest); // 输出 Hello, world! 3.3 读取和写入字符串 在读取用户输入或从文件中读取字符串时，需要确保输入数据以NULL字符结尾。\n1 2 3 char buffer[100]; fgets(buffer, sizeof(buffer), stdin); buffer[strcspn(buffer, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; // 用 NULL 字符替换换行符 四、注意事项 4.1 确保NULL字符存在 在字符串操作时，务必确保字符串以NULL字符结尾，否则可能导致未定义行为或内存访问错误。\n4.2 防止越界写入 在写入字符串数据时，要注意缓冲区大小，防止越界写入，确保不会覆盖NULL字符。\n4.3 正确处理多字节字符 在处理多字节字符（如UTF-8编码）时，要特别注意字符边界和NULL字符的位置。\n总结 NULL字符在C语言中起着重要作用，它标志着字符串的结束，使得字符串处理变得可靠和简便。通过理解NULL字符的作用和使用场景，并注意相关的安全问题，可以更好地编写健壮的C代码。希望这篇博客能帮助你更好地理解和使用NULL字符。\n代码示例 以下是一个结合所有上述概念的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define MAX_LEN 100 int main() { char buffer[MAX_LEN]; printf(\u0026#34;Enter a string: \u0026#34;); if (fgets(buffer, MAX_LEN, stdin) != NULL) { buffer[strcspn(buffer, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; // 确保以 NULL 结尾 printf(\u0026#34;You entered: %s\\n\u0026#34;, buffer); printf(\u0026#34;Length of string: %zu\\n\u0026#34;, strlen(buffer)); } else { printf(\u0026#34;Error reading input.\\n\u0026#34;); } return 0; } 这个示例从用户读取一个字符串，确保其以NULL字符结尾，并输出字符串及其长度。通过这种方式，可以安全地处理用户输入，避免常见的字符串操作错误。\n","permalink":"https://oheyu.github.io/zh/posts/tech/%E7%90%86%E8%A7%A3c%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84null%E5%AD%97%E7%AC%A6/","summary":"在C语言编程中，NULL字符（通常表示为 \\0）是一个关键的概念，尤其在处理字符串时。它标志着字符串的结束，并在许多函数和算法中起着至关重要的","title":"理解C语言中的NULL字符"},{"content":"\r在系统编程中，尤其是文件 I/O 操作中，我们经常需要处理大量数据的读取和写入。为了提高效率，常常使用缓冲机制。本文将详细探讨缓冲性质函数和非缓冲性质函数的区别，以及为何不能在同一文件描述符上交替使用这两种类型的函数。\n一、什么是缓冲性质函数？ 缓冲性质函数是指那些在内部维护一个缓冲区，用于存储从文件描述符读取的数据的函数。这些函数一次读取多个字节的数据到缓冲区中，然后根据用户的请求从缓冲区中返回所需的数据。这种机制可以减少系统调用的次数，从而提高 I/O 操作的效率。\n例如，假设我们有一个 rio_readnb 函数，其功能是从文件描述符 rp 读取最多 n 字节的数据到内存位置 usrbuf。该函数可能会如下实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ssize_t rio_readnb(int fd, void *usrbuf, size_t n) { // 内部维护一个缓冲区 static char buffer[BUFFER_SIZE]; static size_t buffer_count = 0; static char *buffer_ptr = buffer; size_t nleft = n; ssize_t nread; char *bufp = usrbuf; while (nleft \u0026gt; 0) { if (buffer_count == 0) { // 缓冲区为空，从文件描述符读取数据填充缓冲区 if ((nread = read(fd, buffer, sizeof(buffer))) \u0026lt; 0) { if (errno == EINTR) { continue; // 处理信号中断，重试读取 } else { return -1; // 读取错误 } } else if (nread == 0) { break; // 文件结束 } buffer_ptr = buffer; buffer_count = nread; } // 从缓冲区读取数据到用户缓冲区 size_t cnt = (nleft \u0026lt; buffer_count) ? nleft : buffer_count; memcpy(bufp, buffer_ptr, cnt); bufp += cnt; buffer_ptr += cnt; buffer_count -= cnt; nleft -= cnt; } return (n - nleft); // 返回读取的字节数 } 二、什么是非缓冲性质函数？ 非缓冲性质函数则不维护任何内部缓冲区，而是每次调用时直接从文件描述符读取数据并返回给用户。这些函数每次调用都触发系统调用，从而直接从文件描述符读取数据。\n例如，假设我们有一个 rio_readn 函数，其功能是直接从文件描述符读取 n 字节的数据到内存位置 usrbuf，可能会如下实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ssize_t rio_readn(int fd, void *usrbuf, size_t n) { size_t nleft = n; ssize_t nread; char *bufp = usrbuf; while (nleft \u0026gt; 0) { if ((nread = read(fd, bufp, nleft)) \u0026lt; 0) { if (errno == EINTR) { nread = 0; // 处理信号中断，重新读取 } else { return -1; // 读取错误 } } else if (nread == 0) { break; // 文件结束 } nleft -= nread; bufp += nread; } return (n - nleft); // 返回读取的字节数 } 三、缓冲性质函数与非缓冲性质函数为何不能交替使用？ 缓冲性质函数和非缓冲性质函数在同一文件描述符上交替使用会导致数据读取的不一致和错误。这是因为这两种类型的函数在处理文件描述符时的内部机制不同。\n3.1 数据不一致的问题 缓冲性质函数在读取数据时，会一次性从文件描述符读取多个字节的数据到内部缓冲区，然后再从缓冲区返回数据给用户。这意味着文件描述符的读指针会因为读取操作而移动到缓冲区数据的末尾位置。\n如果接着调用非缓冲性质函数，由于它不维护缓冲区，会直接从文件描述符的当前位置读取数据。这会导致以下问题：\n跳过数据：缓冲性质函数已经读取但尚未处理的数据会被非缓冲性质函数跳过，导致数据丢失。 重复读取：非缓冲性质函数移动了文件描述符的读指针，缓冲性质函数的缓冲区数据可能重复被读取。 3.2 示例说明 假设文件内容如下（每个字母代表一个字节）：\n1 abcdef 缓冲性质函数 rio_readnb 读取 4 个字节：\n内部缓冲区读取 abcd，并返回 abcd。 缓冲区现在可能还包含剩余的 ef。 接着调用非缓冲性质函数 rio_readn 读取 2 个字节：\n直接从文件描述符当前位置（即 ef）读取。 返回 ef。 再次调用 rio_readnb 读取 2 个字节：\n缓冲区已失效或被跳过，因为 rio_readn 直接从文件描述符读取，缓冲区未更新。 可能导致数据不一致或错误读取。 3.3 正确的使用方法 为了避免上述问题，应该遵循以下原则：\n保持一致性：在处理同一文件描述符时，要么始终使用缓冲性质函数，要么始终使用非缓冲性质函数。 避免交替使用：不要在同一文件描述符上交替使用这两种类型的函数，以确保数据读取的准确性和一致性。 结论 缓冲性质函数和非缓冲性质函数在处理文件描述符时的内部机制不同，交替使用可能导致数据不一致和错误。因此，在编写系统 I/O 操作时，应注意选择一致的函数类型，以确保数据读取的正确性和程序的稳定性。\n","permalink":"https://oheyu.github.io/zh/posts/tech/%E7%BC%93%E5%86%B2%E6%80%A7%E8%B4%A8%E5%87%BD%E6%95%B0%E4%B8%8E%E9%9D%9E%E7%BC%93%E5%86%B2%E6%80%A7%E8%B4%A8%E5%87%BD%E6%95%B0%E4%B8%BA%E4%BD%95%E4%B8%8D%E8%83%BD%E4%BA%A4%E6%9B%BF%E4%BD%BF%E7%94%A8/","summary":"在系统编程中，尤其是文件 I/O 操作中，我们经常需要处理大量数据的读取和写入。为了提高效率，常常使用缓冲机制。本文将详细探讨缓冲性质函数和非缓冲性","title":"缓冲性质函数与非缓冲性质函数：为何不能交替使用"},{"content":"\rUbuntu 系统快照是一种用于捕捉和保存系统当前状态的技术。这种技术允许用户在将来某个时间点恢复到快照创建时的系统状态。这对于备份、系统更新前的保护、故障恢复以及测试环境的创建非常有用。\n一、系统快照定义 系统快照是操作系统在某个特定时间点上的完整状态，包括所有文件、配置和当前运行状态的副本。通过快照技术，可以快速地恢复系统到之前的某个状态。\n二、原理 系统快照的原理是基于写时复制（Copy-On-Write, COW）技术。当创建一个快照时，系统不会立即复制整个文件系统的数据，而是记录当前所有数据的元数据。只有在数据发生变化时，系统才会将变更部分的数据写入一个新的位置，并更新元数据指向新位置。这种方法节省了大量的存储空间和时间。\n三、实现方式 在 Ubuntu 中，实现系统快照的常见方法有以下几种：\n3.1 使用 LVM（Logical Volume Manager） LVM 提供了逻辑卷管理功能，允许创建卷组、逻辑卷和快照。\n（1）创建快照\n1 lvcreate --size 1G --snapshot --name snap /dev/vg0/lv0 --size：指定快照卷的大小。 --snapshot：指示创建快照。 --name：指定快照卷的名称。 /dev/vg0/lv0：原始逻辑卷的路径。 （2）恢复快照：\n1 lvconvert --merge /dev/vg0/snap --merge：将快照恢复到原始逻辑卷。 3.2 使用 Btrfs 文件系统 Btrfs 是一种现代的 CoW 文件系统，内置了快照功能。\n（1）创建快照：\n1 btrfs subvolume snapshot /path/to/source /path/to/snapshot /path/to/source：源子卷的路径。 /path/to/snapshot：快照的存储路径。 （2）恢复快照：\n1 2 btrfs subvolume delete /path/to/source btrfs subvolume snapshot /path/to/snapshot /path/to/source delete：删除源子卷。 snapshot：从快照创建新的子卷。 3.3 使用 Timeshift Timeshift 是一个专门用于桌面系统的快照工具，提供了图形用户界面（GUI）和命令行界面（CLI）。\n（1）安装 Timeshift：\n1 sudo apt install timeshift （2）创建快照：\n1 sudo timeshift --create --comments \u0026#34;My first snapshot\u0026#34; （3）恢复快照：\n1 sudo timeshift --restore --snapshot \u0026#34;My first snapshot\u0026#34; 四、应用场景 系统备份与恢复：\n在进行系统更新、安装新软件或进行重大配置更改之前创建快照，以便在出现问题时能够快速恢复系统。 测试环境：\n开发人员可以创建系统快照，以便在测试新功能或应用时，能够快速恢复到初始状态，节省重新配置环境的时间。 灾难恢复：\n快照技术可以用于灾难恢复，在系统遭受故障或数据损坏时，能够快速恢复到稳定状态。 虚拟化环境：\n在虚拟化环境中，快照可以用于保存虚拟机的状态，便于在虚拟机出问题时进行快速恢复。 五、优点与局限性 5.1 优点： 快速恢复：可以在几分钟内将系统恢复到之前的状态。 节省空间：通过 CoW 技术，仅保存变更的数据，节省存储空间。 自动化：可以设置定期快照，自动化备份过程。 5.2 局限性： 快照大小限制：快照卷的大小可能受到原始卷的限制，特别是在 LVM 中。 性能影响：频繁创建和恢复快照可能会对系统性能产生影响。 数据一致性：在系统繁忙时创建快照，可能会导致数据不一致，需要确保快照时的数据一致性。 总结 Ubuntu 系统快照是维护系统稳定性和数据安全性的重要工具，通过捕捉系统的当前状态，用户可以在需要时快速恢复到之前的状态。\n","permalink":"https://oheyu.github.io/zh/posts/tech/ubuntu%E7%B3%BB%E7%BB%9F%E5%BF%AB%E7%85%A7%E6%98%AF%E4%B8%AA%E4%BB%80%E4%B9%88%E7%8E%A9%E6%84%8F%E5%84%BF/","summary":"Ubuntu 系统快照是一种用于捕捉和保存系统当前状态的技术。这种技术允许用户在将来某个时间点恢复到快照创建时的系统状态。这对于备份、系统更新前的保护、","title":"Ubuntu系统快照是个什么玩意儿"},{"content":"\r在 Vim 中，我们可以使用重复上一次输入内容的命令来提高编辑效率。以下是几种常用的方法：\n一. 使用 . 命令 . 命令是 Vim 中最常用的重复命令。它可以重复上一次的普通模式命令。例如，如果在普通模式下删除了一个单词（dw），我们可以按 . 来重复这个操作。\n二. 使用 @: 命令 @: 命令可以重复上一次的命令行模式命令。例如，如果在命令行模式下输入了 :s/foo/bar/ 进行替换，我们可以按 @: 来重复这个替换操作。\n三. 使用 q 和 @ 命令记录和播放宏 我们也可以使用 q 命令开始录制宏，然后使用 @ 命令来播放宏，重复执行录制的命令序列，以下是详细步骤：\n录制宏：\n按 q 开始录制宏，后跟一个寄存器名（例如 a），即 qa。 执行你想录制的命令序列。 按 q 结束录制。 播放宏：\n按 @a 播放存储在寄存器 a 中的宏。 以重复删除某个单词为例：\n1 2 3 4 qa \u0026#34; 开始录制宏，寄存器名为 a dw \u0026#34; 删除一个单词 q \u0026#34; 结束录制 @a \u0026#34; 播放寄存器 a 中的宏 四. 使用 @@ 命令 @@ 命令可以重复上一次的宏。例如，如果我们刚刚使用了 @a 播放了宏，你可以按 @@ 来再次播放该宏。\n总结 在 Vim 中，有多种方法可以重复上一次的输入内容：\n使用 . 来重复上一次的普通模式命令。 使用 @: 来重复上一次的命令行模式命令。 使用宏（q 和 @）来录制和重复复杂的命令序列。 使用 @@ 来重复上一次播放的宏。 ","permalink":"https://oheyu.github.io/zh/posts/tech/vim%E9%87%8D%E5%A4%8D%E4%B8%8A%E4%B8%80%E6%AC%A1%E5%91%BD%E4%BB%A4/","summary":"在 Vim 中，我们可以使用重复上一次输入内容的命令来提高编辑效率。以下是几种常用的方法： 一. 使用 . 命令 . 命令是 Vim 中最常用的重复命令。它可以重复上一","title":"Vim重复上一次命令"},{"content":"\r梯度下降是一种核心优化算法，广泛应用于机器学习、深度学习和强化学习中。本文将详细介绍这三者的关系，以及梯度下降在这些领域中的具体应用和实现方式。\n一、机器学习、深度学习和强化学习的关系 1.1 机器学习（Machine Learning, ML） 机器学习是人工智能的一个分支，致力于开发算法和技术，使计算机能够从数据中学习和做出预测或决策，而无需明确的编程指令。其主要类别有：\n监督学习（Supervised Learning）：算法从标记数据中学习，进行分类和回归任务。 无监督学习（Unsupervised Learning）：算法从未标记数据中学习，进行聚类和降维任务。 半监督学习（Semi-supervised Learning）：结合少量标记数据和大量未标记数据进行学习。 强化学习（Reinforcement Learning）：算法通过与环境的互动，从奖励和惩罚中学习最佳策略。 1.2 深度学习（Deep Learning, DL） 深度学习是机器学习的一个子领域，使用多层神经网络（即深度神经网络）来学习复杂数据的表示和模式。其主要特点为：\n层次结构：通过多个隐藏层来提取数据的特征。 自动特征提取：无需人工设计特征，网络能够自动学习数据的表示。 大规模数据处理：适用于处理大量数据，如图像、语音和自然语言处理。 目前而言，最常见架构有两种：\n卷积神经网络（Convolutional Neural Networks, CNNs）：主要用于图像处理。 循环神经网络（Recurrent Neural Networks, RNNs）：主要用于处理序列数据。 1.3 强化学习（Reinforcement Learning, RL） 强化学习是机器学习的一个方法，通过智能体与环境的交互，从反馈信号（奖励或惩罚）中学习最佳行为策略，以最大化累积奖励。其主要特点：\n探索与利用：智能体需要在探索新策略和利用已知最佳策略之间进行平衡。 延迟奖励：动作的效果可能不是立即显现，而是经过一段时间后才表现出来。 策略学习：学习的是一个策略（policy），即在不同状态下采取不同动作的规则。 二、梯度下降在机器学习中的应用 在传统的机器学习中，梯度下降主要用于优化线性回归、逻辑回归和支持向量机等模型的参数。\n2.1 线性回归 线性回归旨在找到一条最佳拟合线来预测目标变量。目标是最小化损失函数（如均方误差）。梯度下降用于更新模型的权重，以逐渐逼近最优解。一般的，线性回归的损失函数可定义为如下形式：\n$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2， $$\n梯度更新公式则为：\n$$ \\theta := \\theta - \\eta \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x^{(i)}。 $$\n2.2 逻辑回归 逻辑回归用于分类任务，目标是最大化对数似然函数。梯度下降用于优化模型参数，使得模型能够更准确地进行分类。一般的，逻辑回归的损失函数（以交叉熵损失函数为例）可定义为如下形式：\n$$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))]， $$\n梯度更新公式则为：\n$$ \\theta := \\theta - \\eta \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x^{(i)}。 $$\n三、梯度下降在深度学习中的应用 在深度学习中，梯度下降通过反向传播算法（backpropagation）来更新神经网络的权重和偏置。深度学习中的梯度下降有多种变体，如随机梯度下降（SGD）、动量梯度下降（Momentum）、自适应学习率方法（如Adam、RMSprop等）。\n3.1 反向传播（Backpropagation） 反向传播是一种计算梯度的高效算法，通过链式法则逐层计算损失函数对每个参数的梯度。其一般步骤为：\n前向传播：计算网络的输出，并根据目标计算损失。 反向传播：从输出层开始，逐层计算损失函数对各层参数的梯度。 参数更新：使用梯度下降算法更新每层的权重和偏置。梯度更新公式为 $\\theta := \\theta - \\eta \\nabla_\\theta J(\\theta)$。 3.2 优化算法 SGD（随机梯度下降）：每次更新只使用一个训练样本的梯度。 Momentum（动量）：在更新中加入前几次梯度的动量项，加速收敛并减小震荡。 $v_t = \\beta v_{t-1} + (1 - \\beta) \\nabla_\\theta J(\\theta)$ $\\theta := \\theta - \\eta v_t$ Adam：结合动量和自适应学习率的优化算法。 $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_\\theta J(\\theta)$ $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla_\\theta J(\\theta))^2$ $\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$ $\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$ $\\theta := \\theta - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$ 四、梯度下降在强化学习中的应用 在强化学习中，梯度下降主要用于策略优化和价值函数逼近。具体应用包括策略梯度方法和深度强化学习。\n4.1 策略梯度方法（Policy Gradient Methods） 策略梯度方法直接优化策略，通过最大化预期累积奖励来更新策略参数。这里有个策略梯度定理（放在这里，供了解）：\n$$ \\nabla_\\theta J(\\theta) = \\mathbb{E}{\\tau \\sim \\pi\\theta} \\left[ \\sum_{t=0}^{T} \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) R(\\tau) \\right] $$\n以及 REINFORCE 算法：\n$$ \\theta := \\theta + \\eta \\sum_{t=0}^{T} \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) R_t $$\n4.2 价值函数逼近（Value Function Approximation） 使用函数逼近方法（如神经网络）来估计价值函数或动作价值函数，通过梯度下降优化这些函数逼近的参数。主要代表是深度 Q 网络（DQN）：\n$$ L(\\theta) = \\mathbb{E}{(s, a, r, s\u0026rsquo;)} \\left[ \\left( r + \\gamma \\max{a\u0026rsquo;} Q(s\u0026rsquo;, a\u0026rsquo;; \\theta^-) - Q(s, a; \\theta) \\right)^2 \\right] $$\n这里，梯度下降用于最小化这个损失函数，从而更新 Q 网络的参数：\n$$ \\theta := \\theta - \\eta \\nabla_\\theta L(\\theta) $$\n4.3 Actor-Critic 方法 Actor-Critic 方法结合了策略梯度和价值函数逼近，将策略（Actor）和价值函数（Critic）分开学习。Actor 使用策略梯度方法更新策略参数：\n$$ \\theta_{\\pi} := \\theta_{\\pi} + \\eta \\nabla_\\theta \\log \\pi_\\theta(a|s) \\delta $$\n而 Critic 则使用 TD 方法或其他价值函数逼近方法更新价值函数参数：\n$$ \\theta_{V} := \\theta_{V} + \\beta \\delta \\nabla_\\theta V(s) $$\n总结 机器学习：梯度下降用于优化传统机器学习模型的参数，如线性回归和逻辑回归。 深度学习：梯度下降通过反向传播优化深层神经网络的权重和偏置，常用的变体包括 SGD、Momentum 和Adam 等。 强化学习：梯度下降用于策略优化和价值函数逼近，通过策略梯度、深度 Q 网络和 Actor-Critic 方法等实现。 ","permalink":"https://oheyu.github.io/zh/posts/tech/%E7%90%86%E8%A7%A3%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","summary":"梯度下降是一种核心优化算法，广泛应用于机器学习、深度学习和强化学习中。本文将详细介绍这三者的关系，以及梯度下降在这些领域中的具体应用和实现方","title":"理解梯度下降在机器学习、深度学习和强化学习中的应用"},{"content":"\r在机器学习和深度学习中，梯度下降是一种广泛使用的优化算法，用于最小化模型的损失函数，从而优化模型参数。梯度下降的三种主要变体是批量梯度下降、随机梯度下降和小批量梯度下降。本文将详细介绍这三种方法的定义、优缺点，以及它们在损失函数（准确度）曲线上的整体表现。\n一、批量梯度下降（Batch Gradient Descent） 1.1 定义 批量梯度下降（Batch Gradient Descent）在每次迭代时，使用整个训练集计算损失函数的梯度，并基于这个梯度来更新模型参数。损失函数 $J(\\theta)$ 通常是所有样本损失的平均值。例如，如果训练集中有 $N$ 个样本，则损失函数可以表示为：\n$$ J(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L(f(x^{(i)}; \\theta), y^{(i)})。 $$\n其中，$f(x^{(i)}; \\theta)$ 是模型的预测，$y^{(i)}$ 是第 $i$ 个样本的真实标签，$L$ 是损失函数（例如均方误差或交叉熵损失）。每次迭代的参数更新公式为：\n$$ \\theta := \\theta - \\eta \\cdot \\nabla_\\theta J(\\theta)。 $$\n1.2优点 稳定性高：每次参数更新使用整个训练集的梯度，梯度估计准确，更新稳定。 收敛性好：更容易接近全局最优解。 1.3 缺点 计算成本高：每次迭代都需要计算整个训练集的梯度，尤其对于大型数据集，计算成本非常高。 内存消耗大：需要在内存中存储整个训练集，内存消耗大。 二、随机梯度下降（Stochastic Gradient Descent, SGD） 2.1定义 随机梯度下降在每次迭代时，仅使用一个样本计算损失函数的梯度，并基于这个梯度来更新模型参数。损失函数 $J(\\theta; x^{(i)}, y^{(i)})$ 是第 $i$ 个样本的损失函数。每次迭代的参数更新公式为：\n$$ \\theta := \\theta - \\eta \\cdot \\nabla_\\theta J(\\theta; x^{(i)}, y^{(i)}) $$\n2.2优点 计算成本低：每次迭代只需计算一个样本的梯度，计算成本低。 快速更新：由于每次迭代计算量小，参数更新频繁，初期收敛速度快。 2.3 缺点 梯度估计噪声大：每次更新的梯度波动大，导致优化路径不稳定。 收敛性差：容易在局部最优解附近震荡，难以收敛到全局最优解。 三、小批量梯度下降（Mini-batch Gradient Descent） 3.1 定义 小批量梯度下降是批量梯度下降和随机梯度下降的折中方案。每次迭代时，使用一个小批量样本（mini-batch）计算梯度，并基于这个梯度来更新模型参数。损失函数 $J(\\theta; B)$ 是一个小批量 $B$ 样本的平均损失。每次迭代的参数更新公式为：\n$$ \\theta := \\theta - \\eta \\cdot \\nabla_\\theta J(\\theta; B) $$\n3.2 优点 计算效率高：相比批量梯度下降，每次迭代计算的小批量样本梯度减少了计算成本。 收敛速度快：相比随机梯度下降，更新更加稳定，减少了震荡。 硬件效率：可以利用GPU加速计算，提高计算效率。 3.3 缺点 需要调参：需要选择合适的小批量大小，影响性能。 复杂度增加：相对于随机梯度下降和批量梯度下降，算法实现复杂度增加。 四、三者之间的联系与区别 4.1 联系 目标一致：三种方法都旨在通过梯度下降优化损失函数，以找到模型参数的最优值。 基本原理相同：三种方法的核心都是基于梯度下降，即使用损失函数的梯度来更新模型参数。 4.2 区别 数据使用方式： 批量梯度下降：使用整个训练集计算梯度。 随机梯度下降：每次迭代只使用一个样本计算梯度。 小批量梯度下降：每次迭代使用一个小批量样本计算梯度。 计算成本： 批量梯度下降：计算成本最高，因为每次迭代计算整个训练集的梯度。 随机梯度下降：计算成本最低，因为每次迭代只计算一个样本的梯度。 小批量梯度下降：计算成本介于两者之间。 收敛速度与稳定性： 批量梯度下降：更新稳定，收敛速度较慢。 随机梯度下降：初期收敛速度快，但更新不稳定，容易震荡。 小批量梯度下降：折中了两者的优点，更新较稳定，收敛速度较快。 内存消耗： 批量梯度下降：需要在内存中存储整个训练集。 随机梯度下降：内存消耗最小，只需存储一个样本。 小批量梯度下降：内存消耗介于两者之间，只需存储一个小批量样本。 五、反映在损失函数曲线和准确度曲线上的表现 5.1 批量梯度下降 损失函数曲线：曲线平滑，稳步下降，趋向于全局最优解。 准确度曲线：曲线平滑，准确度稳步上升，最终趋于收敛。 5.2 随机梯度下降 损失函数曲线：曲线波动大，总体趋势下降，但存在震荡和噪声。 准确度曲线：曲线波动大，总体上升，但有时会明显下降。 5.3 小批量梯度下降 损失函数曲线：曲线相对平滑，但有一些波动，介于批量和随机之间。 准确度曲线：曲线相对平稳，但有一些波动，总体上升。 总结 批量梯度下降、随机梯度下降和小批量梯度下降是机器学习和深度学习中常见的优化算法。它们在计算成本、收敛速度和更新稳定性上各有优缺点。相比较批量梯度下降与随机梯度下降，小批量梯度下降通过结合两者的优点，广泛应用于实际深度学习任务中。\n","permalink":"https://oheyu.github.io/zh/posts/tech/%E7%90%86%E8%A7%A3%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E4%B8%8E%E5%B0%8F%E6%89%B9%E9%87%8F%E7%9A%84%E5%AF%B9%E6%AF%94/","summary":"在机器学习和深度学习中，梯度下降是一种广泛使用的优化算法，用于最小化模型的损失函数，从而优化模型参数。梯度下降的三种主要变体是批量梯度下降、","title":"理解梯度下降：批量、随机与小批量的对比"},{"content":"\r在 Vim 的普通模式下，我们可以将光标放在括号内的任意位置输入如下命令快速删除括号（圆括号()、方括号[]、花括号{}）里的内容：\ndi(：删除当前括号对内的内容（但不删除括号本身）。其中，d 是删除命令，i( 表示括号 () 内的内容（i 表示 “inner”，内层）。 da(：删除当前括号对以及括号内的内容。其中，d 是删除命令，a( 表示括号 () 内的内容（a 表示 “around”，包括括号本身）。 对于方括号 [] 、花括号 {} 以及其他配对符号，如\u0026quot;\u0026quot;、''、\u0026lt;\u0026gt;等，使用方法与前述类似。 此外，在 Vim 的普通模式下，可以使用 vi* 或 va* 选择括号内的内容，并进入可视模式。\n","permalink":"https://oheyu.github.io/zh/posts/tech/vim%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%88%A0%E9%99%A4%E6%8B%AC%E5%8F%B7%E9%87%8C%E7%9A%84%E5%86%85%E5%AE%B9/","summary":"在 Vim 的普通模式下，我们可以将光标放在括号内的任意位置输入如下命令快速删除括号（圆括号()、方括号[]、花括号{}）里的内容： di(：删除当前","title":"Vim如何快速删除括号里的内容"},{"content":"\r大端序（Big-endian） 数据的高字节存储在低地址，低字节存储在高地址。即，大端序是从“最高有效字节（Most Significant Byte, MSB）”到“最低有效字节（Least Significant Byte, LSB）”按序排列的。\n小端序（Little-endian） 数据的低字节存储在低地址，高字节存储在高地址。即，小端序是从“最低有效字节”到“最高有效字节”按序排列的。\n","permalink":"https://oheyu.github.io/zh/posts/tech/%E5%A4%A7%E7%AB%AF%E5%BA%8F%E4%B8%8E%E5%B0%8F%E7%AB%AF%E5%BA%8F/","summary":"大端序（Big-endian） 数据的高字节存储在低地址，低字节存储在高地址。即，大端序是从“最高有效字节（Most Significant Byte, MSB）”到“最低有效","title":"大端序与小端序"},{"content":"\r结构体（Struct） 结构体是一种用户定义的数据类型，允许将不同类型的变量组合在一起作为一个单一的实体进行处理。结构体常用于组织和管理不同类型的数据，使代码更具可读性和可维护性。结构体有如下三个关键特性：\n成员独立：结构体中的每个成员都有自己的内存空间，不同成员之间互不干扰；\n顺序存储：结构体中的成员按照声明的顺序依次存储在内存中，但可能存在字节填充（padding）以满足对齐要求；\n类型混合：结构体中可以包含不同类型的数据成员，例如整型、浮点型和字符数组等。\n以下是一个简短的代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; struct Person { char name[50]; int age; float height; }; int main() { Person person = {\u0026#34;Alice\u0026#34;, 30, 1.75}; std::cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; person.name \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Age: \u0026#34; \u0026lt;\u0026lt; person.age \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Height: \u0026#34; \u0026lt;\u0026lt; person.height \u0026lt;\u0026lt; std::endl; return 0; } 联合体（Union） 同样的，联合体也是一种用户自定义的数据类型，允许将多个不同类型的变量存储在同一个内存位置。它常用于节省内存，尤其在需要处理多种数据类型但某一时刻只会使用其中一种的情况下。联合体有如下三个关键特性：\n共享内存：联合体中的所有成员共享同一块内存，某一时刻只能有一个成员是有效的；\n节省空间：联合体的大小等于其最大成员的大小；\n类型混合：同样可以包含不同类型的数据成员，但某一时刻只能使用某一个成员变量。\n以下是一个简短的示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; union Data { int intValue; float flaotValue; char charValue; }; int main() { Data data; data.intValue = 10; std::cout \u0026lt;\u0026lt; \u0026#34;Integer: \u0026#34; \u0026lt;\u0026lt; data.intValue \u0026lt;\u0026lt; std::endl; data.floatValue = 3.14; std::cout \u0026lt;\u0026lt; \u0026#34;Float: \u0026#34; \u0026lt;\u0026lt; data.floatValue \u0026lt;\u0026lt; std::endl; data.charValue = \u0026#39;A\u0026#39;; std::cout \u0026lt;\u0026lt; \u0026#34;Char: \u0026#34; \u0026lt;\u0026lt; data.charValue \u0026lt;\u0026lt; std::endl; return 0; } 结构体与联合体的对比分析 结构体 联合体 内存管理 每个成员都有独立的内存空间 所有成员共享同一内存空间 大小 所有成员大小之和（加上可能的填充字节） 最大成员的大小 数据有效性 结构体变量有效期中，所有成员始终有效 某一时刻，只能有一个成员有效 用途 数据记录、函数返回多个值 嵌入式系统节省内存、硬件寄存器访问 ","permalink":"https://oheyu.github.io/zh/posts/tech/%E7%BB%93%E6%9E%84%E4%BD%93%E4%B8%8E%E8%81%94%E5%90%88%E4%BD%93/","summary":"结构体（Struct） 结构体是一种用户定义的数据类型，允许将不同类型的变量组合在一起作为一个单一的实体进行处理。结构体常用于组织和管理不同类","title":"结构体与联合体"},{"content":"\r解释型语言 解释型语言是被解释器逐行解释和执行源代码的语言。这意味着程序代码在运行时将被直接翻译为机器代码并执行。\n解释型语言有以下三个优点以及一个缺点：\n即时执行：代码在运行时被逐行解释，没有预编译的过程； 跨平台：解释器有不同平台的发行版本，同样的代码可以在多个操作系统上被执行； 调试友好：由于代码是被逐行解释和执行，调试和测试过程相对简单，可以即时查看和修改代码的效果； 速度较慢：由于每次运行都需要解释代码，执行速度通常比编译型语言慢。 常见的解释型语言有：Python、JavaScript、Ruby等。\n编译型语言 编译型语言有以下特点：\n预编译：代码在运行前需要经过编译器完成编译，生成独立的可执行文件； 执行速度快：由于编译后的代码时机器代码，可以直接由硬件执行，运行速度通常比解释型语言快； 平台依赖性：编译后的可执行文件通常与特定的平台和操作系统绑定，跨平台需要重新编译源代码； 调试复杂：由于代码在编译前不能运行，调试过程复杂，需要依赖编译器提供的调试工具。 常见的编译型语言有：C、C++、Rust、Go等\n","permalink":"https://oheyu.github.io/zh/posts/tech/%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80%E4%B8%8E%E7%BC%96%E8%AF%91%E5%9E%8B%E8%AF%AD%E8%A8%80/","summary":"解释型语言 解释型语言是被解释器逐行解释和执行源代码的语言。这意味着程序代码在运行时将被直接翻译为机器代码并执行。 解释型语言有以下三个优点以及","title":"解释型语言与编译型语言"},{"content":"\r在C、C++语言中，将源代码文件转换成可执行文件涉及多个步骤，主要包括预处理、编译、汇编和链接。\n源代码（Source code）文件 源代码文件包含了一系列人类可读的计算机语言指令。在 C 语言规范中，源代码文件通常以 .c 为拓展名；而在 C++ 语言规范中，源代码文件通常以 .cpp 为拓展名。\n预处理（Preprocessing） 预处理是编译过程的第一步。在这个过程中，预处理器处理源代码文件中以 # 开头的指令。这些指令包括头文件 #include、宏定义 #define 替换、条件编译 #ifdef 等。预处理的结果是一个 “拓展源代码” 文件，通常以 .i 为拓展名。具体来说，“拓展源代码” 是在原始源代码的基础上，展开所有的宏，插入所有头文件的内容，处理所有的条件编译。\n假设有如下的C++源代码文件 “main.cpp” ：\n1 2 3 4 5 6 7 8 // main.cpp #include \u0026lt;iostream\u0026gt; #define PI 3.1415926 int main() { std::cout \u0026lt;\u0026lt; \u0026#34;PI value is \u0026#34; \u0026lt;\u0026lt; PI \u0026lt;\u0026lt; std::endl; return 0; } 预处理后的代码将不包含 “#include” 和 “#define” 指令，而是包含了 “iostream” 的全部内容并替换 “PI” 的值：\n1 2 3 4 5 6 7 // main.i // iostream 内容展开 // 例如 std::ostream, std::cout等的定义 int main() { std::cout \u0026lt;\u0026lt; \u0026#34;PI value is \u0026#34; \u0026lt;\u0026lt; 3.1415926 \u0026lt;\u0026lt; std::endl; return 0; } 编译（Compilation） 编译器将预处理后的代码转换为目标平台的汇编语言。这一步涉及语法分析、语义分析与优化等。编译器输出的是汇编代码，通常以 .s 为拓展名，这些汇编指令是平台相关的，表示如何在特定的硬件上执行程序。编译后的汇编代码可能看起来像这样（以x86平台为例）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 .section .rodata .LC0: .string \u0026#34;PI value is %f\\n\u0026#34; .text .globl main main: pushq %rbp movq %rsp, %rbp subq $16, %rsp movss $0x40490fdb, -4(%rbp) // PI value as float movq $LC0, %rdi leaq -4(%rbp), %rsi call printf movl $0, %eax leave ret 汇编（Assembly） 汇编器将汇编代码转换为机器代码，即二进制指令，这些指令可以由计算机的 CPU 直接执行。汇编器生成的是对象文件（Object file），通常以 .o（Unix/Linux系统）或 .obj（Windows系统）为拓展名。对象文件包含了编译后的代码的机器语言版本，但这些代码还未进行地址绑定。对象文件是二进制文件，通常不可读，但它包含了函数和数据的二进制表示。\n为什么汇编阶段不完成地址绑定? 在汇编阶段，代码被转换成机器可执行的指令。然而，指令中引用的函数和全局变量的具体内存地址通常尚未确定。这些引用被暂时标记为“待定”，直到链接阶段才会被解析和绑定。出现这种情况的原因如下：\n多模块程序：一个大型程序通常由多个源代码文件组成。经过 “预处理、编译、汇编” 这三个步骤后，每个源代码文件会被独立地转换成对象文件。在这个过程中，汇编器仅能处理当前模块中的符号（如函数、全局变量等），而无法得知其他模块中定义的符号的具体地址。因此，在汇编时，这些跨模块的引用会被标记为待定。 库连接：程序可能依赖于多个外部库，这些库在编译和汇编时也是被独立处理的。因此，库函数的具体内存地址在汇编阶段是未知的，汇编器无法将这些地址填入生成的指令中。这些库函数的地址同样会在链接阶段由链接器解析和绑定。 对于上述问题，汇编器和链接器通过重定位解决这一问题：\n重定位记录：汇编器生成的对象文件中包括机器指令和一些符号表，其中符号表记录了未解析的符号及其引用位置。对于同一模块内定义和使用的符号（例如局部变量），汇编器可以直接将地址填入机器指令中；而对于跨模块引用的符号（例如其他源文件或库中的函数和全局变量），汇编器会生成 “重定位表”，标记这些符号为未解析，并记录它们在目标文件中的位置。 链接：在链接阶段，链接器将所有对象文件和库文件合并成一个可执行文件。链接器首先扫描所有目标文件的符号表，构建全局符号表（Global Symbol Table），该表包含了所有模块中定义的符号及其相对地址。接着，链接器通过重定位表，将未解析的符号地址替换为它们在最终可执行文件中的实际地址。链接器将所有模块的代码和数据段重定位到最终的内存地址空间中，这样每个符号都能正确地被引用。 链接（Linking） 链接器处理一个或多个对象文件，解决外部符号引用，可能还会链接运行时库等。链接器将所有对象文件及所需的库文件集合在一起，生成最终的可执行文件（在Windows上是 .exe，在Unix/Linux上通常没有扩展名）。链接器生成的可执行文件包含了所有必要的程序代码、数据和运行时库的引用，这些都已经是准备好可以被操作系统加载和执行的格式。最终的可执行文件实现了特定平台上的 “一次编译，多次运行”。\n","permalink":"https://oheyu.github.io/zh/posts/tech/%E6%BA%90%E6%96%87%E4%BB%B6%E5%88%B0%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%87%E7%A8%8B/","summary":"在C、C++语言中，将源代码文件转换成可执行文件涉及多个步骤，主要包括预处理、编译、汇编和链接。 源代码（Source code）文件 源代码文件","title":"源文件到可执行文件的过程"}]